# config.example.toml

[common]
active_model = "deepseek"
active_vision_model = "aliyunvl"

[openai]
model = "gpt-4o"
api_key = "YOUR_OPENAI_API_KEY"
base_url = "https://api.openai.com/v1"
temperature = 0.7

[deepseek]
model = "deepseek-chat"
api_key = "YOUR_DEEPSEEK_API_KEY"
base_url = "https://api.deepseek.com"
temperature = 0.0

[aliyun]
model = "qwen-plus"
api_key = "YOUR_ALIYUN_API_KEY"
base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
temperature = 0.0

[aliyunvl]
model = "qwen-vl-max-latest"
api_key = "YOUR_ALIYUN_API_KEY"
base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
temperature = 0.7

[anthropic]
model = "anthropic/claude-3.7-sonnet"
api_key = "YOUR_ANTHROPIC_API_KEY"
org_id = "YOUR_ORG_ID"
base_url = "https://openrouter.ai/api/v1"
temperature = 0.7
